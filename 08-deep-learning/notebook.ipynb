{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7094cad",
   "metadata": {},
   "source": [
    "# 8. Neural networks and deep learning\n",
    "\n",
    "This week, we'll learn about neural nets and build a model\n",
    "for classifying images of clothes\n",
    "\n",
    "\n",
    "## 8.1 Fashion classification\n",
    "\n",
    "Dataset: \n",
    "\n",
    "* Full: https://github.com/alexeygrigorev/clothing-dataset\n",
    "* Small: https://github.com/alexeygrigorev/clothing-dataset-small\n",
    "\n",
    "Links:\n",
    "\n",
    "* https://cs231n.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone git@github.com:alexeygrigorev/clothing-dataset-small.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12765d10",
   "metadata": {},
   "source": [
    "## 8.2 TensorFlow and Keras\n",
    "\n",
    "* Installing TensorFlow\n",
    "* Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "start_time = timeit.timeit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "  print(f\"GPU set_memory_growth SUCCESS\")\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53990556",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "\n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "print(f\"The notebook starting time  is : {start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059cd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clothing-dataset-small/train/t-shirt'\n",
    "name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'\n",
    "fullname = f'{path}/{name}'\n",
    "load_img(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(fullname, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ba0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is not yet scaled, values range [0.0, 255.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3928249",
   "metadata": {},
   "source": [
    "## 8.3 Pre-trained convolutional neural networks\n",
    "\n",
    "* Imagenet dataset: https://www.image-net.org/\n",
    "* Pre-trained models: https://keras.io/api/applications/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df763eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5660b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is now scaled [-1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2d908",
   "metadata": {},
   "source": [
    "Because imagenet \n",
    "\n",
    "> offer tens of millions of cleanly labeled and sorted images for most of the concepts in the WordNet hierarchy\n",
    "\n",
    "the images may not be what we are trying to classify for our own projects. So, the need of transfer learning / reinforcement learning, using our own dense layers by excluding Xception's dense layers with `include_top=False` when we train with our own images.\n",
    "\n",
    "## 8.4 Convolutional neural networks\n",
    "\n",
    "* Types of layers: convolutional and dense \n",
    "* Convolutional layers and filters\n",
    "* Dense layers\n",
    "\n",
    "There are more layers. Read here: https://cs231n.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf118bf",
   "metadata": {},
   "source": [
    "## 8.5 Transfer learning\n",
    "\n",
    "* Reading data with `ImageDataGenerator`\n",
    "* Train `Xception` on smaller images (150x150)\n",
    "\n",
    "(Better to run it with a GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181633a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f88c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17973f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,          # do not include Dense layers\n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "# freeze convolutional layers\n",
    "base_model.trainable = False    \n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "# the \"long thing\"\n",
    "base = base_model(inputs, training=False)       \n",
    "# slice the \"long thing\"\n",
    "vectors = keras.layers.GlobalAveragePooling2D()(base) \n",
    "\n",
    "outputs = keras.layers.Dense(10)(vectors)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.shape\n",
    "# 32 x 5 x 5 x 2048 before pooling\n",
    "# 32 x 2048         after pooling\n",
    "# 32 x 10           make Dense, into our 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2083a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "# more than Adam optimizers exists, experiment!\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)  \n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def hours_minutes(td):\n",
    "    return td.seconds//3600, (td.seconds//60)%60\n",
    "\n",
    "def minutes_second(td):\n",
    "    minutes  = (td.seconds//60)%60\n",
    "    seconds = td.seconds - minutes*60\n",
    "    return minutes, seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "\n",
    "history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\")\n",
    "\n",
    "# 5mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def1b4b",
   "metadata": {},
   "source": [
    "## 8.6 Adjusting the learning rate\n",
    "\n",
    "* What's the learning rate\n",
    "* Trying different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62596012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "# ----------------------------------------- #\n",
    "scores = {}\n",
    "\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    print(lr)\n",
    "\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[lr] = history.history\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "# ----------------------------------------- #\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\")  \n",
    "# 17mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5329752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del scores[0.1]\n",
    "# del scores[0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14096c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, hist in scores.items():\n",
    "    plt.plot(hist['accuracy'], label=('train=%s' % lr))\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f906434",
   "metadata": {},
   "source": [
    "## 8.7 Checkpointing\n",
    "\n",
    "* Saving the best model only\n",
    "* Training a model with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/model_v1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13755c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chechpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'models/xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5689f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "# ----------------------------------------- #\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = make_model(learning_rate=learning_rate)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[chechpoint]\n",
    ")\n",
    "# ----------------------------------------- #\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\")  \n",
    "# 5mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d7b9b",
   "metadata": {},
   "source": [
    "## 8.8 Adding more layers\n",
    "\n",
    "\n",
    "* Adding one inner dense layer\n",
    "* Experimenting with different sizes of inner layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(inner)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4288d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "# ----------------------------------------- #\n",
    "learning_rate = 0.001\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for size in [10, 100, 1000]:\n",
    "    print(size)\n",
    "\n",
    "    model = make_model(learning_rate=learning_rate, size_inner=size)\n",
    "    history = model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
    "    scores[size] = history.history\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "# ----------------------------------------- #\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\") \n",
    "# 12mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % size))\n",
    "\n",
    "plt.xticks(np.arange(10))\n",
    "plt.yticks([0.78, 0.80, 0.82, 0.825, 0.83])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1849b",
   "metadata": {},
   "source": [
    "## 8.9 Regularization and dropout\n",
    "\n",
    "* Regularizing by freezing a part of the network\n",
    "* Adding dropout to our model\n",
    "* Experimenting with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae364d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01, size_inner=100, droprate=0.5):\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(150, 150, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "# ----------------------------------------- #\n",
    "learning_rate = 0.001\n",
    "size = 100\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for droprate in [0.0, 0.2, 0.5, 0.8]:\n",
    "    print(droprate)\n",
    "\n",
    "    model = make_model(\n",
    "        learning_rate=learning_rate,\n",
    "        size_inner=size,\n",
    "        droprate=droprate\n",
    "    )\n",
    "\n",
    "    history = model.fit(train_ds, epochs=30, validation_data=val_ds)\n",
    "    scores[droprate] = history.history\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "# ----------------------------------------- #\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\") \n",
    "\n",
    "#  50mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for droprate, hist in scores.items():\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % droprate))\n",
    "\n",
    "# plt.ylim(0.78, 0.86)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0690ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = scores[0.0]\n",
    "plt.plot(hist['val_accuracy'], label=0.0)\n",
    "\n",
    "hist = scores[0.2]\n",
    "plt.plot(hist['val_accuracy'], label=0.2)\n",
    "\n",
    "plt.legend()\n",
    "#plt.plot(hist['accuracy'], label=('val=%s' % droprate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042866c",
   "metadata": {},
   "source": [
    "## 8.10 Data augmentation\n",
    "\n",
    "* Different data augmentations\n",
    "* Training a model with augmentations\n",
    "* How to select data augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     vertical_flip=True,\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cb784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "# ----------------------------------------- #\n",
    "learning_rate = 0.001\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "model = make_model(\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds)\n",
    "# ----------------------------------------- #\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\") \n",
    "\n",
    "# 20mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beaea4b",
   "metadata": {},
   "source": [
    "## 8.11 Training a larger model\n",
    "\n",
    "* Train a 299x299 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_size=150, learning_rate=0.01, size_inner=100,\n",
    "               droprate=0.5):\n",
    "\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(input_size, input_size, 3)\n",
    "    )\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5294b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2edbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'models/xception_v4_1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cell = timeit.default_timer()\n",
    "# ----------------------------------------- #\n",
    "learning_rate = 0.0005\n",
    "size = 100\n",
    "droprate = 0.2\n",
    "\n",
    "model = make_model(\n",
    "    input_size=input_size,\n",
    "    learning_rate=learning_rate,\n",
    "    size_inner=size,\n",
    "    droprate=droprate\n",
    ")\n",
    "\n",
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds,\n",
    "                   callbacks=[checkpoint])\n",
    "\n",
    "# ----------------------------------------- #\n",
    "elapsed = timeit.default_timer() - start_cell\n",
    "mins, secs = minutes_second(datetime.timedelta(seconds=elapsed))\n",
    "print(f\"cell execution time: {mins} minutes {secs} seconds\") \n",
    "\n",
    "# took 50 mins wsl+gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "hist = history.history\n",
    "plt.plot(hist['val_accuracy'], label='val')\n",
    "plt.plot(hist['accuracy'], label='train')\n",
    "\n",
    "plt.legend()\n",
    "#plt.plot(hist['accuracy'], label=('val=%s' % droprate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce7ef6",
   "metadata": {},
   "source": [
    "## 8.12 Using the model\n",
    "\n",
    "* Loading the model\n",
    "* Evaluating the model\n",
    "* Getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af9154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/test',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9643701",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/xception_v4_1_37_0.894.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda51aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaac061",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clothing-dataset-small/test/pants/c8d21106-bbdb-4e8d-83e4-bf3d14e54c16.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e90085",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(path, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd31e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f3ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img)\n",
    "X = np.array([x])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27444d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800b96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(classes, pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the op several times.\n",
    "print('Time (s) to run notebook in local vs-code with GTX 970')\n",
    "\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(f'CPU (s): {cpu_time}')\n",
    "print()\n",
    "\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(f'GPU (s): {gpu_time}')\n",
    "print()\n",
    "print(f'GPU speedup over CPU: {int(cpu_time/gpu_time)}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[elapsed to timedelta](https://stackoverflow.com/a/51846797)<br>\n",
    "[timedelta components](https://stackoverflow.com/a/2119512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "hours, mins = hours_minutes(datetime.timedelta(seconds=elapsed))\n",
    "\n",
    "print(f\"The notebook completion time  is : {hours} hours and {mins} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263dbd8",
   "metadata": {},
   "source": [
    "## 8.13 Summary\n",
    "\n",
    "* We can use pre-trained models for general image classification\n",
    "* Convolutional layers let us turn an image into a vector\n",
    "* Dense layers use the vector to make the predictions\n",
    "* Instead of training a model from scratch, we can use transfer learning and re-use already trained convolutional layers\n",
    "* First, train a small model (150x150) before training a big one (299x299)\n",
    "* Learning rate - how fast the model trians. Fast learners aren't always best ones\n",
    "* We can save the best model using callbacks and checkpointing\n",
    "* To avoid overfitting, use dropout and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5378439",
   "metadata": {},
   "source": [
    "## 8.14 Explore more\n",
    "\n",
    "* Add more data, e.g. Zalando, etc (ADD LINKS)\n",
    "* Albumentations - another way of generating augmentations\n",
    "* Use PyTorch or MXNet instead of TensorFlow/Keras\n",
    "* In addition to Xception, there are others architectures - try them \n",
    "\n",
    "Other projects:\n",
    "\n",
    "* cats vs dogs\n",
    "* Hotdog vs not hotdog\n",
    "* Category of images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.15 Hyperparameter optimization with KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/alexeygrigorev/mlbookcamp-code/releases/download/chapter7-model/xception_v4_large_08_0.894.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.00005, 0.0001, 0.001, 0.01, 0.1]\n",
    "size = [10, 100, 1000]\n",
    "droprate = [0.0, 0.2, 0.5, 0.8]\n",
    "\n",
    "def build_model(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(\n",
    "      hp.Choice('units', [8, 16, 32]),\n",
    "      activation='relu'))\n",
    "  model.add(keras.layers.Dense(1, activation='relu'))\n",
    "  model.compile(loss='mse')\n",
    "  return model\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     vertical_flip=True,\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,          # do not include Dense layers\n",
    "    input_shape=(150, 150, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "            # Tune the activation function to use.\n",
    "            activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "        )\n",
    "    )\n",
    "    # Tune whether to use dropout.\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "This notebook runs smoothly due to code snippets I used from these notebooks and posts. My thanks to the authors for the guides/answers.\n",
    "\n",
    "- [tensorflow and libraries versions, tensorflow install](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/manual_setup.ipynb)\n",
    "- https://www.tensorflow.org/guide/gpu\n",
    "- [cpu() and gpu() code](https://colab.research.google.com/notebooks/gpu.ipynb)\n",
    "- [elapsed to timedelta](https://stackoverflow.com/a/51846797)\n",
    "- [timedelta components](https://stackoverflow.com/a/2119512)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
